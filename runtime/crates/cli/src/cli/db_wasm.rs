use core::{CommandSpec, Context, Registry, SubcommandSpec};
use serde::{Deserialize, Serialize};
use std::collections::BTreeSet;
use std::fs;
use std::path::{Path, PathBuf};
use std::time::{SystemTime, UNIX_EPOCH};
use stdio::{error, log};

const GENERATE: SubcommandSpec = SubcommandSpec {
    name: "generate",
    summary: "generate db client and migration artifacts",
    aliases: &["gen"],
    handler: cmd_generate,
};

const MIGRATE: SubcommandSpec = SubcommandSpec {
    name: "migrate",
    summary: "apply pending db migrations (browser metadata mode)",
    aliases: &[],
    handler: cmd_migrate,
};

const INFO: SubcommandSpec = SubcommandSpec {
    name: "info",
    summary: "show db generation and migration status",
    aliases: &["status"],
    handler: cmd_info,
};

const FLUSH: SubcommandSpec = SubcommandSpec {
    name: "flush",
    summary: "reset db migration metadata (browser metadata mode)",
    aliases: &[],
    handler: cmd_flush,
};

const SUBCOMMANDS: &[SubcommandSpec] = &[GENERATE, MIGRATE, INFO, FLUSH];

const COMMAND: CommandSpec = CommandSpec {
    name: "db",
    category: "database",
    summary: "database tooling (platform-gated)",
    aliases: &[],
    subcommands: SUBCOMMANDS,
    handler: cmd,
};

const GENERATED_HEADER: &str = "/*\n\
 * AUTO-GENERATED FILE - DO NOT EDIT\n\
 * Generated by deka db generate\n\
 * Changes will be overwritten.\n\
 */\n\n";

#[derive(Debug, Clone, Serialize, Deserialize)]
struct DbState {
    source: String,
    generated_at_unix: i64,
    model_count: usize,
    models: Vec<String>,
    engine: String,
    location: String,
    migration_files: Vec<String>,
    applied_migrations: Vec<String>,
    mode: String,
}

pub fn register(registry: &mut Registry) {
    registry.add_command(COMMAND);
}

fn cmd(_context: &Context) {
    error(
        "db",
        "missing subcommand. use: deka db generate|migrate|info|flush",
    );
}

fn cmd_generate(context: &Context) {
    let cwd = &context.env.cwd;
    let source = match resolve_generate_input(cwd, context.args.positionals.first()) {
        Ok(path) => path,
        Err(message) => {
            error("db generate", &message);
            return;
        }
    };

    let source_text = match fs::read_to_string(&source) {
        Ok(value) => value,
        Err(err) => {
            error(
                "db generate",
                &format!("failed to read model entry {}: {}", source.display(), err),
            );
            return;
        }
    };

    let models = extract_struct_names(&source_text);
    if models.is_empty() {
        error(
            "db generate",
            &format!(
                "no struct models found in {}. define at least one `struct Name {{ ... }}`",
                source.display()
            ),
        );
        return;
    }

    let cfg = read_db_config(cwd);

    let generated = match generate_db_artifacts(cwd, &source, &models, &cfg.engine, &cfg.location) {
        Ok(value) => value,
        Err(message) => {
            error("db generate", &message);
            return;
        }
    };

    log(
        "db generate",
        &format!(
            "generated {} files from {} model(s) in {}",
            generated,
            models.len(),
            source.display()
        ),
    );
}

fn cmd_migrate(context: &Context) {
    let cwd = &context.env.cwd;
    let db_dir = cwd.join("db");
    let migrations_dir = db_dir.join("migrations");
    let state_path = db_dir.join("_state.json");

    if !migrations_dir.is_dir() {
        error(
            "db migrate",
            "db/migrations directory not found. run `deka db generate <models>` first",
        );
        return;
    }

    let mut migration_files = match collect_migration_files(&migrations_dir) {
        Ok(value) => value,
        Err(message) => {
            error("db migrate", &message);
            return;
        }
    };
    migration_files.sort();

    let mut state = match read_state(&state_path) {
        Ok(value) => value,
        Err(message) => {
            error("db migrate", &message);
            return;
        }
    };

    let applied: BTreeSet<String> = state.applied_migrations.iter().cloned().collect();
    let mut newly_applied = Vec::new();
    for file in &migration_files {
        if !applied.contains(file) {
            newly_applied.push(file.clone());
        }
    }

    if newly_applied.is_empty() {
        log("db migrate", "no pending migrations");
        return;
    }

    for name in &newly_applied {
        state.applied_migrations.push(name.clone());
    }
    state.migration_files = migration_files.clone();

    if let Err(err) = fs::write(
        &state_path,
        serde_json::to_string_pretty(&state).unwrap_or_default(),
    ) {
        error("db migrate", &format!("failed to write state: {}", err));
        return;
    }

    log(
        "db migrate",
        &format!(
            "applied {} migration(s) in browser metadata mode: {}",
            newly_applied.len(),
            newly_applied.join(", ")
        ),
    );
    log(
        "db migrate",
        "note: browser mode currently updates migration state only; SQL apply is handled by host DB runtime",
    );
}

fn cmd_info(context: &Context) {
    let cwd = &context.env.cwd;
    let state_path = cwd.join("db").join("_state.json");
    let state = match read_state(&state_path) {
        Ok(value) => value,
        Err(message) => {
            error("db info", &message);
            return;
        }
    };

    let migration_count = state.migration_files.len();
    let applied_count = state.applied_migrations.len();
    let pending_count = migration_count.saturating_sub(applied_count);

    log("db info", &format!("source: {}", state.source));
    log("db info", &format!("models: {}", state.model_count));
    log(
        "db info",
        &format!("generated_at_unix: {}", state.generated_at_unix),
    );
    log("db info", &format!("engine: {}", state.engine));
    log("db info", &format!("location: {}", state.location));
    log("db info", &format!("migration_files: {}", migration_count));
    log("db info", &format!("applied_migrations: {}", applied_count));
    log("db info", &format!("pending_migrations: {}", pending_count));
    log("db info", &format!("mode: {}", state.mode));
}

fn cmd_flush(context: &Context) {
    let cwd = &context.env.cwd;
    let state_path = cwd.join("db").join("_state.json");
    let mut state = match read_state(&state_path) {
        Ok(value) => value,
        Err(message) => {
            error("db flush", &message);
            return;
        }
    };

    state.applied_migrations.clear();
    if let Err(err) = fs::write(
        &state_path,
        serde_json::to_string_pretty(&state).unwrap_or_default(),
    ) {
        error("db flush", &format!("failed to write state: {}", err));
        return;
    }

    log(
        "db flush",
        "cleared applied migration metadata in browser mode",
    );
}

fn resolve_generate_input(cwd: &Path, input: Option<&String>) -> Result<PathBuf, String> {
    let raw = input
        .map(String::as_str)
        .filter(|s| !s.trim().is_empty())
        .unwrap_or("types/index.phpx");
    let candidate = if let Some(stripped) = raw.strip_prefix("@/") {
        cwd.join(stripped)
    } else {
        cwd.join(raw)
    };
    resolve_model_entry(&candidate, raw)
}

fn resolve_model_entry(candidate: &Path, raw: &str) -> Result<PathBuf, String> {
    if candidate.is_file() {
        if candidate.extension().and_then(|v| v.to_str()) != Some("phpx") {
            return Err(format!("expected a .phpx model entry file, got: {}", raw));
        }
        return Ok(candidate.to_path_buf());
    }

    if candidate.is_dir() {
        let index = candidate.join("index.phpx");
        if index.is_file() {
            return Ok(index);
        }
        return Err(format!(
            "expected model entry file, got directory: {}. tried: {}/index.phpx",
            raw,
            raw.trim_end_matches('/')
        ));
    }

    Err(format!(
        "model input not found: {}. pass a .phpx file or a directory containing index.phpx",
        raw
    ))
}

fn extract_struct_names(source: &str) -> Vec<String> {
    let bytes = source.as_bytes();
    let mut i = 0usize;
    let mut out = Vec::<String>::new();
    while i + 6 < bytes.len() {
        if source[i..].starts_with("struct") {
            let before_ok = i == 0 || !is_ident_char(bytes[i - 1]);
            let after = i + 6;
            let after_ok = after >= bytes.len() || !is_ident_char(bytes[after]);
            if before_ok && after_ok {
                let mut j = after;
                while j < bytes.len() && bytes[j].is_ascii_whitespace() {
                    j += 1;
                }
                let start = j;
                while j < bytes.len() && is_ident_char(bytes[j]) {
                    j += 1;
                }
                if j > start {
                    let name = &source[start..j];
                    if is_exportable_model_name(name) {
                        out.push(name.to_string());
                    }
                }
                i = j;
                continue;
            }
        }
        i += 1;
    }

    out.sort();
    out.dedup();
    out
}

fn is_ident_char(ch: u8) -> bool {
    ch.is_ascii_alphanumeric() || ch == b'_' || ch == b'$'
}

fn is_exportable_model_name(name: &str) -> bool {
    let first = name.as_bytes().first().copied().unwrap_or_default();
    first.is_ascii_alphabetic() || first == b'_'
}

#[derive(Debug, Clone)]
struct DbConfig {
    engine: String,
    location: String,
}

fn read_db_config(cwd: &Path) -> DbConfig {
    let path = cwd.join("deka.json");
    let raw = fs::read_to_string(path).unwrap_or_default();
    let parsed: serde_json::Value = serde_json::from_str(&raw).unwrap_or(serde_json::Value::Null);
    let db = parsed.get("db").and_then(|v| v.as_object());

    let engine = db
        .and_then(|obj| obj.get("engine"))
        .and_then(|v| v.as_str())
        .map(|v| v.trim().to_ascii_lowercase())
        .filter(|v| !v.is_empty())
        .unwrap_or_else(|| "sqlite".to_string());

    let location = db
        .and_then(|obj| obj.get("location"))
        .and_then(|v| v.as_str())
        .map(|v| v.trim().to_string())
        .filter(|v| !v.is_empty())
        .unwrap_or_else(|| "./deka.sqlite".to_string());

    DbConfig { engine, location }
}

fn generate_db_artifacts(
    cwd: &Path,
    source: &Path,
    models: &[String],
    engine: &str,
    location: &str,
) -> Result<usize, String> {
    let db_dir = cwd.join("db");
    let generated_dir = db_dir.join(".generated");
    let migrations_dir = db_dir.join("migrations");
    fs::create_dir_all(&generated_dir)
        .map_err(|e| format!("failed to create db/.generated: {}", e))?;
    fs::create_dir_all(&migrations_dir)
        .map_err(|e| format!("failed to create db/migrations: {}", e))?;

    let index_path = db_dir.join("index.phpx");
    let client_path = db_dir.join("client.phpx");
    let meta_path = db_dir.join("meta.phpx");
    let state_path = db_dir.join("_state.json");
    let migration_path = migrations_dir.join("0001_init.sql");
    let schema_path = generated_dir.join("schema.json");

    let state = DbState {
        source: source.display().to_string(),
        generated_at_unix: SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .map(|d| d.as_secs() as i64)
            .unwrap_or(0),
        model_count: models.len(),
        models: models.to_vec(),
        engine: engine.to_string(),
        location: location.to_string(),
        migration_files: vec!["0001_init.sql".to_string()],
        applied_migrations: Vec::new(),
        mode: "browser".to_string(),
    };

    let index_body = format!(
        "{}import {{ connect, query, exec, close, stats }} from 'db'\nexport {{ connect, query, exec, close, stats }}\n",
        GENERATED_HEADER
    );

    let client_body = format!(
        "{}import {{ open_handle as __open, query as __query, exec as __exec, close as __close, stats as __stats }} from 'db'\n\nexport function connect($name = '{}') {{\n  return __open($name)\n}}\n\nexport function query($h, $sql, $params = []) {{\n  return __query($h, $sql, $params)\n}}\n\nexport function exec($h, $sql, $params = []) {{\n  return __exec($h, $sql, $params)\n}}\n\nexport function close($h) {{\n  return __close($h)\n}}\n\nexport function stats() {{\n  return __stats()\n}}\n",
        GENERATED_HEADER,
        location.replace('\\', "\\\\").replace('"', "\\\"")
    );

    let mut meta_entries = String::new();
    for name in models {
        meta_entries.push_str(&format!("  '{}' => ['name' => '{}'],\n", name, name));
    }
    let meta_body = format!(
        "{}export function models() {{\n  return [\n{}  ]\n}}\n",
        GENERATED_HEADER, meta_entries
    );

    let migration_body = render_init_migration(models);
    let schema_body = serde_json::to_string_pretty(&serde_json::json!({
        "models": models,
        "engine": engine,
        "location": location,
    }))
    .unwrap_or_else(|_| "{}".to_string());

    fs::write(&index_path, index_body)
        .map_err(|e| format!("failed to write {}: {}", index_path.display(), e))?;
    fs::write(&client_path, client_body)
        .map_err(|e| format!("failed to write {}: {}", client_path.display(), e))?;
    fs::write(&meta_path, meta_body)
        .map_err(|e| format!("failed to write {}: {}", meta_path.display(), e))?;
    fs::write(
        &state_path,
        serde_json::to_string_pretty(&state).unwrap_or_else(|_| "{}".to_string()),
    )
    .map_err(|e| format!("failed to write {}: {}", state_path.display(), e))?;
    fs::write(&migration_path, migration_body)
        .map_err(|e| format!("failed to write {}: {}", migration_path.display(), e))?;
    fs::write(&schema_path, schema_body)
        .map_err(|e| format!("failed to write {}: {}", schema_path.display(), e))?;

    Ok(6)
}

fn render_init_migration(models: &[String]) -> String {
    let mut out = String::new();
    out.push_str("-- Generated by deka db generate (browser mode)\n\n");
    for model in models {
        let table = to_table_name(model);
        out.push_str(&format!(
            "create table if not exists \"{}\" (\n  id integer primary key,\n  name text not null,\n  version text\n);\n\n",
            table
        ));
    }
    out
}

fn to_table_name(model: &str) -> String {
    let mut out = String::new();
    for (idx, ch) in model.chars().enumerate() {
        if ch.is_ascii_uppercase() {
            if idx > 0 {
                out.push('_');
            }
            out.push(ch.to_ascii_lowercase());
        } else {
            out.push(ch.to_ascii_lowercase());
        }
    }
    if !out.ends_with('s') {
        out.push('s');
    }
    out
}

fn read_state(path: &Path) -> Result<DbState, String> {
    if !path.exists() {
        return Err("db/_state.json not found. run `deka db generate <models>` first".to_string());
    }
    let raw = fs::read_to_string(path)
        .map_err(|e| format!("failed to read {}: {}", path.display(), e))?;
    serde_json::from_str::<DbState>(&raw)
        .map_err(|e| format!("failed to parse {}: {}", path.display(), e))
}

fn collect_migration_files(migrations_dir: &Path) -> Result<Vec<String>, String> {
    let mut out = Vec::new();
    let entries = fs::read_dir(migrations_dir)
        .map_err(|e| format!("failed to read {}: {}", migrations_dir.display(), e))?;
    for entry in entries {
        let entry = entry.map_err(|e| format!("failed to read migration entry: {}", e))?;
        let path = entry.path();
        if !path.is_file() {
            continue;
        }
        if path.extension().and_then(|v| v.to_str()) != Some("sql") {
            continue;
        }
        let name = path
            .file_name()
            .and_then(|v| v.to_str())
            .ok_or_else(|| "invalid migration filename".to_string())?
            .to_string();
        out.push(name);
    }
    Ok(out)
}
